{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppgh2zicYvoZ"
      },
      "source": [
        "# Import important libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6mc36BjYuan"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "from IPython.display import display, Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import numpy as np\n",
        "from PIL import Image as PILImage\n",
        "import easyocr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize EasyOCR reader (this should be done once for efficiency)\n",
        "reader = easyocr.Reader(['ar'], gpu=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifcMhoGKa7oo"
      },
      "source": [
        "# Face of id card without need to rotate .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "EvSokdyzWmmG",
        "outputId": "d2f5bc97-4ce1-450d-ccdd-4f242e3ce50b"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess the cropped image\n",
        "def preprocess_image(cropped_image):\n",
        "    gray_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
        "    blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
        "    threshold_image = cv2.adaptiveThreshold(blurred_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 17, 2)\n",
        "    return threshold_image\n",
        "\n",
        "# Functions for specific fields with custom OCR configurations\n",
        "def extract_text(image, bbox, lang='ara'):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    cropped_image = image[y1:y2, x1:x2]\n",
        "    preprocessed_image = preprocess_image(cropped_image)\n",
        "    results = reader.readtext(preprocessed_image, detail=0, paragraph=True)\n",
        "    text = ' '.join(results)\n",
        "    return text.strip()\n",
        "\n",
        "# Function to detect national ID numbers in a cropped image\n",
        "def detect_national_id(cropped_image):\n",
        "    model = YOLO('detect_id.pt')  # Load the model directly in the function\n",
        "    results = model(cropped_image)\n",
        "    detected_info = []\n",
        "\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            cls = int(box.cls)\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            detected_info.append((cls, x1))\n",
        "            cv2.rectangle(cropped_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(cropped_image, str(cls), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
        "\n",
        "    detected_info.sort(key=lambda x: x[1])\n",
        "    id_number = ''.join([str(cls) for cls, _ in detected_info])\n",
        "    \n",
        "    return id_number\n",
        "\n",
        "# Function to remove numbers from a string\n",
        "def remove_numbers(text):\n",
        "    return re.sub(r'\\d+', '', text)\n",
        "\n",
        "# Function to plot image with bounding boxes\n",
        "def plot_image_with_boxes(image, boxes):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    ax = plt.gca()\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = [int(coord) for coord in box]\n",
        "        rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, color='red', linewidth=2)\n",
        "        ax.add_patch(rect)\n",
        "    plt.show()\n",
        "\n",
        "# Function to expand bounding box height only\n",
        "def expand_bbox_height(bbox, scale=1.2, image_shape=None):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    width = x2 - x1\n",
        "    height = y2 - y1\n",
        "    center_x = x1 + width // 2\n",
        "    center_y = y1 + height // 2\n",
        "    new_height = int(height * scale)\n",
        "    new_y1 = max(center_y - new_height // 2, 0)\n",
        "    new_y2 = min(center_y + new_height // 2, image_shape[0])\n",
        "    return [x1, new_y1, x2, new_y2]\n",
        "\n",
        "# Function to process the cropped image\n",
        "def process_image(cropped_image):\n",
        "    # Load the trained YOLO model for objects (fields) detection\n",
        "    model = YOLO('detect_odjects.pt')\n",
        "    results = model(cropped_image)\n",
        "\n",
        "    # Variables to store extracted values\n",
        "    first_name = ''\n",
        "    second_name = ''\n",
        "    merged_name = ''\n",
        "    nid = ''\n",
        "    address = ''\n",
        "    serial = ''\n",
        "\n",
        "    # Loop through the results\n",
        "    for result in results:\n",
        "        result.show()  # Shows the image with bounding boxes\n",
        "        output_path = 'd2.jpg'\n",
        "        result.save(output_path)\n",
        "        display(Image(filename=output_path))\n",
        "\n",
        "        boxes = [box.xyxy[0].tolist() for box in result.boxes]\n",
        "        plot_image_with_boxes(cropped_image, boxes)\n",
        "\n",
        "        for box in result.boxes:\n",
        "            bbox = box.xyxy[0].tolist()\n",
        "            class_id = int(box.cls[0].item())\n",
        "            class_name = result.names[class_id]\n",
        "            bbox = [int(coord) for coord in bbox]\n",
        "\n",
        "            if class_name == 'firstName':\n",
        "                first_name = extract_text(cropped_image, bbox, lang='ara')\n",
        "            elif class_name == 'lastName':\n",
        "                second_name = extract_text(cropped_image, bbox, lang='ara')\n",
        "            elif class_name == 'serial':\n",
        "                serial = extract_text(cropped_image, bbox, lang='eng')\n",
        "            elif class_name == 'address':\n",
        "                address = extract_text(cropped_image, bbox, lang='ara')\n",
        "                address = remove_numbers(address)\n",
        "            elif class_name == 'nid':\n",
        "                expanded_bbox = expand_bbox_height(bbox, scale=1.5, image_shape=cropped_image.shape)\n",
        "                cropped_nid = cropped_image[expanded_bbox[1]:expanded_bbox[3], expanded_bbox[0]:expanded_bbox[2]]\n",
        "                nid = detect_national_id(cropped_nid)\n",
        "\n",
        "    merged_name = f\"{first_name} {second_name}\"\n",
        "    print(f\"First Name: {first_name}\")\n",
        "    print(f\"Second Name: {second_name}\")\n",
        "    print(f\"Full Name: {merged_name}\")\n",
        "    print(f\"National ID: {nid}\")\n",
        "    print(f\"Address: {address}\")\n",
        "    print(f\"Serial: {serial}\")\n",
        "\n",
        "    decoded_info = decode_egyptian_id(nid)\n",
        "    for key, value in decoded_info.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "# Function to decode the Egyptian ID number\n",
        "def decode_egyptian_id(id_number):\n",
        "    governorates = {\n",
        "        '01': 'Cairo',\n",
        "        '02': 'Alexandria',\n",
        "        '03': 'Port Said',\n",
        "        '04': 'Suez',\n",
        "        '11': 'Damietta',\n",
        "        '12': 'Dakahlia',\n",
        "        '13': 'Ash Sharqia',\n",
        "        '14': 'Kaliobeya',\n",
        "        '15': 'Kafr El - Sheikh',\n",
        "        '16': 'Gharbia',\n",
        "        '17': 'Monoufia',\n",
        "        '18': 'El Beheira',\n",
        "        '19': 'Ismailia',\n",
        "        '21': 'Giza',\n",
        "        '22': 'Beni Suef',\n",
        "        '23': 'Fayoum',\n",
        "        '24': 'El Menia',\n",
        "        '25': 'Assiut',\n",
        "        '26': 'Sohag',\n",
        "        '27': 'Qena',\n",
        "        '28': 'Aswan',\n",
        "        '29': 'Luxor',\n",
        "        '31': 'Red Sea',\n",
        "        '32': 'New Valley',\n",
        "        '33': 'Matrouh',\n",
        "        '34': 'North Sinai',\n",
        "        '35': 'South Sinai',\n",
        "        '88': 'Foreign'\n",
        "    }\n",
        "\n",
        "    if len(id_number) != 14:\n",
        "        raise ValueError(\"ID number must be 14 digits long\")\n",
        "\n",
        "    century_digit = int(id_number[0])\n",
        "    year = int(id_number[1:3])\n",
        "    month = int(id_number[3:5])\n",
        "    day = int(id_number[5:7])\n",
        "    governorate_code = id_number[7:9]\n",
        "    gender_code = int(id_number[12:13])\n",
        "\n",
        "    if century_digit == 2:\n",
        "        century = \"1900-1999\"\n",
        "        full_year = 1900 + year\n",
        "    elif century_digit == 3:\n",
        "        century = \"2000-2099\"\n",
        "        full_year = 2000 + year\n",
        "    else:\n",
        "        raise ValueError(\"Invalid century digit\")\n",
        "\n",
        "    gender = \"Male\" if gender_code % 2 != 0 else \"Female\"\n",
        "    governorate = governorates.get(governorate_code, \"Unknown\")\n",
        "    birth_date = f\"{full_year:04d}-{month:02d}-{day:02d}\"\n",
        "\n",
        "    return {\n",
        "        'Birth Date': birth_date,\n",
        "        'Governorate': governorate,\n",
        "        'Gender': gender\n",
        "    }\n",
        "\n",
        "# Function to detect the ID card and pass it to the existing code\n",
        "def detect_and_process_id_card(image_path):\n",
        "    # Load the ID card detection model\n",
        "    id_card_model = YOLO('detect_id_card.pt')\n",
        "\n",
        "    # Perform inference to detect the ID card\n",
        "    id_card_results = id_card_model(image_path)\n",
        "\n",
        "    # Load the original image using OpenCV\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Crop the ID card from the image\n",
        "    for result in id_card_results:\n",
        "        for box in result.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])  # Get bounding box coordinates\n",
        "            cropped_image = image[y1:y2, x1:x2]\n",
        "\n",
        "    # Pass the cropped image to the existing processing function\n",
        "    process_image(cropped_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "detect_and_process_id_card('font_ID.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-miSAorbdJW"
      },
      "source": [
        "# Back of id card"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "IhBAat7EbDq_",
        "outputId": "9af63181-7675-45e9-930c-d8bbd8103563"
      },
      "outputs": [],
      "source": [
        "# Load the YOLO models\n",
        "model_id_card = YOLO('detect_id_card.pt')  # Model for detecting ID cards\n",
        "model_job = YOLO('detect_odjects.pt')  # Model for extracting objects field\n",
        "\n",
        "# Function to preprocess the cropped image\n",
        "def preprocess_image(cropped_image):\n",
        "    gray_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
        "    blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
        "    threshold_image = cv2.adaptiveThreshold(blurred_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 17, 2)\n",
        "    return threshold_image\n",
        "\n",
        "# Functions for specific fields with custom OCR configurations\n",
        "def extract_text(image, bbox, lang='ara'):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    cropped_image = image[y1:y2, x1:x2]\n",
        "    preprocessed_image = preprocess_image(cropped_image)\n",
        "    results = reader.readtext(preprocessed_image, detail=0, paragraph=True)\n",
        "    text = ' '.join(results)\n",
        "    return text.strip()\n",
        "\n",
        "# Function to plot image with bounding boxes\n",
        "def plot_image_with_boxes(image, boxes):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    ax = plt.gca()\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = [int(coord) for coord in box]\n",
        "        rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, color='red', linewidth=2)\n",
        "        ax.add_patch(rect)\n",
        "    plt.show()\n",
        "\n",
        "# Function to detect ID card using the ID card detection model\n",
        "def detect_id_card(image_path, model):\n",
        "    results = model(image_path)\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    id_card_bboxes = []\n",
        "    for result in results:\n",
        "        # Extract bounding boxes\n",
        "        id_card_bboxes.extend([box.xyxy[0].tolist() for box in result.boxes])\n",
        "\n",
        "    return image, id_card_bboxes\n",
        "\n",
        "# Function to process ID card image and extract job field\n",
        "def process_image(image_path, model_id_card, model_job):\n",
        "    # Detect ID card\n",
        "    image, id_card_bboxes = detect_id_card(image_path, model_id_card)\n",
        "\n",
        "    # Assuming only one ID card detected, process the first one\n",
        "    if id_card_bboxes:\n",
        "        bbox = id_card_bboxes[0]  # Get the first detected ID card bbox\n",
        "\n",
        "        # Crop the ID card region\n",
        "        x1, y1, x2, y2 = [int(coord) for coord in bbox]\n",
        "        id_card_image = image[y1:y2, x1:x2]\n",
        "\n",
        "        # Use the cropped ID card image as input for the job detection model\n",
        "        results = model_job(id_card_image)  # Pass the cropped image directly\n",
        "\n",
        "        # Loop through the results\n",
        "        job = ''\n",
        "        for result in results:\n",
        "            # Display the results\n",
        "            result.show()  # Shows the image with bounding boxes\n",
        "\n",
        "            # Save the output image\n",
        "            output_path = 'job_output.jpg'\n",
        "            result.save(output_path)\n",
        "\n",
        "            # Visualize the saved output image\n",
        "            display(Image(filename=output_path))\n",
        "\n",
        "            # Extract bounding boxes and class names\n",
        "            boxes = [box.xyxy[0].tolist() for box in result.boxes]\n",
        "            plot_image_with_boxes(id_card_image, boxes)  # Use id_card_image for plotting\n",
        "\n",
        "            # Extract text for the \"job\" field\n",
        "            for box in result.boxes:\n",
        "                bbox = box.xyxy[0].tolist()  # Get bounding box coordinates\n",
        "                class_id = int(box.cls[0].item())  # Get class ID\n",
        "                class_name = result.names[class_id]  # Get class name\n",
        "\n",
        "                # Convert bounding box coordinates to integers\n",
        "                bbox = [int(coord) for coord in bbox]\n",
        "\n",
        "                if class_name == 'job':\n",
        "                    job = extract_text(id_card_image, bbox, lang='ara')\n",
        "\n",
        "        # Print the extracted value\n",
        "        print(f\"Job: {job}\")\n",
        "    else:\n",
        "        print(\"No ID card detected\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RANTY0EY1M9J"
      },
      "outputs": [],
      "source": [
        "\n",
        "process_image('font_ID.jpg', model_id_card, model_job)  # Use the uploaded image"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
